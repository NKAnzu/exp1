{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8423628",
   "metadata": {},
   "source": [
    "# 8-11. 프로젝트 : 네이버 영화리뷰 감성분석 도전하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53b722b",
   "metadata": {},
   "source": [
    "라이브러리 버전을 확인해 봅니다\n",
    "\n",
    "사용할 라이브러리 버전을 둘러봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b334d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.3\n",
      "0.5.2\n",
      "4.1.2\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import konlpy\n",
    "import gensim\n",
    "import tensorflow as tf\n",
    "import os \n",
    "print(pandas.__version__)\n",
    "print(konlpy.__version__)\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3eaae5",
   "metadata": {},
   "source": [
    "# 1) 데이터 준비와 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9f6dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f628df",
   "metadata": {},
   "source": [
    "# 2) 데이터로더 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a500f49",
   "metadata": {},
   "source": [
    "실습 때 다루었던 IMDB 데이터셋은 텍스트를 가공하여 imdb.data_loader() 메서드를 호출하면 숫자 인덱스로 변환된 텍스트와 word_to_index 딕셔너리까지 친절하게 제공합니다. \n",
    "\n",
    "그러나 이번에 다루게 될 nsmc 데이터셋은 전혀 가공되지 않은 텍스트 파일로 이루어져 있습니다. \n",
    "\n",
    "이것을 읽어서 imdb.data_loader()와 동일하게 동작하는 자신만의 data_loader를 만들어 보는 것으로 시작합니다. \n",
    "\n",
    "data_loader 안에서는 다음을 수행해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5a3ad2",
   "metadata": {},
   "source": [
    "- 데이터의 중복 제거\n",
    "- NaN 결측치 제거\n",
    "- 한국어 토크나이저로 토큰화 (tokenize)\n",
    "- 불용어(Stopwords) 제거 (\n",
    "- 사전word_to_index 구성 (단어를 index로)\n",
    "- 텍스트 스트링을 사전 인덱스 스트링으로 변환 (embedding)\n",
    "- X_train, y_train, X_test, y_test, word_to_index 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7715770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([25857, 55737, 110014, 126782, 140721], dtype='int64')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['document'].isna()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0db01712",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39d3d36",
   "metadata": {},
   "source": [
    "결측값 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23e28201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, document, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['label'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a149caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop_duplicates(['document','label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5598dfb3",
   "metadata": {},
   "source": [
    "train_data의 중복값과 결측치를 제거한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d3b1cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>6222902</td>\n",
       "      <td>인간이 문제지.. 소는 뭔죄인가..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>8549745</td>\n",
       "      <td>평점이 너무 낮아서...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>9311800</td>\n",
       "      <td>이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>2376369</td>\n",
       "      <td>청춘 영화의 최고봉.방황과 우울했던 날들의 자화상</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>9619869</td>\n",
       "      <td>한국 영화 최초로 수간하는 내용이 담긴 영화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146339 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                           document  label\n",
       "0        9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1        3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2       10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3        9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4        6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
       "...          ...                                                ...    ...\n",
       "149995   6222902                                인간이 문제지.. 소는 뭔죄인가..      0\n",
       "149996   8549745                                      평점이 너무 낮아서...      1\n",
       "149997   9311800                    이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?      0\n",
       "149998   2376369                        청춘 영화의 최고봉.방황과 우울했던 날들의 자화상      1\n",
       "149999   9619869                           한국 영화 최초로 수간하는 내용이 담긴 영화      0\n",
       "\n",
       "[146339 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f64c87f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = Mecab() #한국어 토크나이저\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다'] #불용어 stopwords\n",
    "\n",
    "#사전word_to_index 구성 (단어를 index로)\n",
    "#텍스트 스트링을 사전 인덱스 스트링으로 변환 (embedding)\n",
    "#X_train, y_train, X_test, y_test, word_to_index 리턴\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "    \n",
    "    X_train=[]\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # temp_X에는 문장각 내용 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords]\n",
    "        X_train.append(temp_X)\n",
    "        \n",
    "    X_test=[]\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "        \n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    \n",
    "    counter= counter.most_common(10000-4)\n",
    "    vocab=['', '', '', ''] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "    \n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['']for word in wordlist]\n",
    "    \n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "    \n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])),word_to_index\n",
    "\n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3518e192",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b41e0f",
   "metadata": {},
   "source": [
    "X_train, X_test는 각 단어의 토큰 index가 저장된다.\n",
    "\n",
    "y_train, y_test는 라벨값이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a223a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7ae88e",
   "metadata": {},
   "source": [
    "# 3) 모델 구성을 위한 데이터 분석 및 가공\n",
    "\n",
    "데이터셋 내 문장 길이 분포\n",
    "\n",
    "적절한 최대 문장 길이 지정\n",
    "\n",
    "keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d71d78e",
   "metadata": {},
   "source": [
    "num_tokens에 각 문장에 대해서 단어 갯수를 구한다. 그거의 np.array를 놓음 즉 문장길이 지정을 위해서 배열로 놓는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdd77948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  15.96940191154864\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  12.843571191092\n",
      "pad_sequences maxlen :  41\n",
      "전체 문장의 0.9342988343341575%가 maxlen 설정값 이내에 포함됩니다.\n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(X_train) + list(X_test)\n",
    "num_tokens=[len(tokens) for tokens in total_data_text]\n",
    "num_tokens= np.array(num_tokens)\n",
    "\n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다.'.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d30e8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 41)\n"
     ]
    }
   ],
   "source": [
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_to_index[''],\n",
    "                                                        padding='pre', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index[''],\n",
    "                                                       padding='pre', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c6581e",
   "metadata": {},
   "source": [
    "# 4) 모델 구성 및 validation set 구성\n",
    "모델은 3가지 이상 다양하게 구성하여 실험해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c347ebc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 8-9\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8)) \n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) # 최종 출력은 긍정/부정을 나타내는 dim입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257bfe19",
   "metadata": {},
   "source": [
    "# 5) 모델 훈련 개시\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a239f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation 20000개\n",
    "X_val = X_train[-20000:]\n",
    "y_val = y_train[-20000:]\n",
    "\n",
    "#validation set을 제외한 나머지 15000건\n",
    "partial_X_train = X_train[:-20000]\n",
    "partial_y_train = y_train[:-20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37d8fd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "247/247 [==============================] - 5s 7ms/step - loss: 0.5097 - accuracy: 0.7607 - val_loss: 0.3773 - val_accuracy: 0.8391\n",
      "Epoch 2/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.3449 - accuracy: 0.8553 - val_loss: 0.3540 - val_accuracy: 0.8468\n",
      "Epoch 3/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.3207 - accuracy: 0.8670 - val_loss: 0.3514 - val_accuracy: 0.8476\n",
      "Epoch 4/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.3095 - accuracy: 0.8724 - val_loss: 0.3507 - val_accuracy: 0.8494\n",
      "Epoch 5/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.3002 - accuracy: 0.8760 - val_loss: 0.3594 - val_accuracy: 0.8438\n",
      "Epoch 6/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.2910 - accuracy: 0.8805 - val_loss: 0.3592 - val_accuracy: 0.8423\n",
      "Epoch 7/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.2824 - accuracy: 0.8850 - val_loss: 0.3557 - val_accuracy: 0.8481\n",
      "Epoch 8/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.2741 - accuracy: 0.8882 - val_loss: 0.3578 - val_accuracy: 0.8475\n",
      "Epoch 9/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.2649 - accuracy: 0.8925 - val_loss: 0.3631 - val_accuracy: 0.8450\n",
      "Epoch 10/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.2556 - accuracy: 0.8978 - val_loss: 0.3705 - val_accuracy: 0.8451\n",
      "Epoch 11/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.2464 - accuracy: 0.9016 - val_loss: 0.3728 - val_accuracy: 0.8480\n",
      "Epoch 12/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.2375 - accuracy: 0.9058 - val_loss: 0.3841 - val_accuracy: 0.8439\n",
      "Epoch 13/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.2279 - accuracy: 0.9094 - val_loss: 0.3887 - val_accuracy: 0.8426\n",
      "Epoch 14/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.2186 - accuracy: 0.9134 - val_loss: 0.3984 - val_accuracy: 0.8442\n",
      "Epoch 15/20\n",
      "247/247 [==============================] - 1s 5ms/step - loss: 0.2116 - accuracy: 0.9157 - val_loss: 0.4115 - val_accuracy: 0.8444\n",
      "Epoch 16/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.2029 - accuracy: 0.9199 - val_loss: 0.4197 - val_accuracy: 0.8429\n",
      "Epoch 17/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.1972 - accuracy: 0.9225 - val_loss: 0.4473 - val_accuracy: 0.8425\n",
      "Epoch 18/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.1898 - accuracy: 0.9258 - val_loss: 0.4502 - val_accuracy: 0.8421\n",
      "Epoch 19/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.1841 - accuracy: 0.9288 - val_loss: 0.4620 - val_accuracy: 0.8415\n",
      "Epoch 20/20\n",
      "247/247 [==============================] - 1s 6ms/step - loss: 0.1779 - accuracy: 0.9316 - val_loss: 0.4825 - val_accuracy: 0.8414\n"
     ]
    }
   ],
   "source": [
    "#model 학습을 시작해 봅시다.\n",
    "model.compile(optimizer='adam',\n",
    "              loss ='binary_crossentropy',\n",
    "              metrics=(['accuracy'])\n",
    "             )\n",
    "epochs=20\n",
    "history = model.fit(partial_X_train, partial_y_train,epochs=epochs,\n",
    "          batch_size=512,\n",
    "          validation_data=(X_val, y_val),\n",
    "          verbose=1\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4b663ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.4886 - accuracy: 0.8401\n",
      "[0.4885745644569397, 0.8401041626930237]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51870639",
   "metadata": {},
   "source": [
    "# 6) Loss, Accuracy 그래프 시각화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7798d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "#model.fit() 과정 중의 train/validation loss, accuracy 등이 매 epoch마다 history 변수에 저장되어 있습니다.\n",
    "history_dict = history.history\n",
    "print(history_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95bcf1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다.\n",
    "plt.plot(epochs, loss, 'bo', label='Training_loss')\n",
    "# 'b'는 파란색 실선이다.\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation_loss')\n",
    "plt.title('Training, and  Validation Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81452812",
   "metadata": {},
   "source": [
    "# 7) 학습된 Embedding 레이어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41abb294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape) # shape: (vocab_size, embedding_dim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8d8c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/exploration/word2vec.txt'\n",
    "\n",
    "f= open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim)) #몇개의 벡터를 얼마의 사이즈로 기재할지 \n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4, vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57eb6e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.20728523,  0.10288877,  0.0937077 , -0.14378497,  0.10947222,\n",
       "        0.1259484 ,  0.09809761, -0.07850978, -0.13718002, -0.0623871 ,\n",
       "       -0.21761651,  0.10238208, -0.15372705, -0.13577   , -0.1230868 ,\n",
       "        0.10220447], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "\n",
    "vector = word_vectors['사랑']\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fb9a80",
   "metadata": {},
   "source": [
    "'사랑'에 대한 wordvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a65964a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('요괴', 0.9605420231819153),\n",
       " ('사라질', 0.9572589993476868),\n",
       " ('이소룡', 0.9546595215797424),\n",
       " ('판사', 0.9546411633491516),\n",
       " ('카이', 0.9539645314216614),\n",
       " ('여신', 0.9502131938934326),\n",
       " ('찌질이', 0.9496913552284241),\n",
       " ('일리', 0.949455976486206),\n",
       " ('짱', 0.9490277171134949),\n",
       " ('깊', 0.9487717151641846)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 워드 벡터가 의미 벡터 공간상에 유의미하게 학습되었는지 확인하는 방법 중에, \n",
    "# 단어를 하나 주고 그와 가장 유사한 단어와 그 유사도를 확인하는 방법이 있습니다. gensim을 사용하면 아래와 같이 해볼 수 있습니다.\n",
    "word_vectors.similar_by_word(\"사랑\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6545f5d5",
   "metadata": {},
   "source": [
    "'헉'에 대해서 유사도가 높은 순서대로 단어들을 출력해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d3ec2d",
   "metadata": {},
   "source": [
    "# 8) 한국어 Word2Vec 임베딩 활용하여 성능 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72338518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/aiffel/aiffel/exploration/word2vec.txt'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f11dff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "word2vec_file_path = os.getenv(\"HOME\")+'/data/word2vec_ko.model'\n",
    "word_vectors2 = Word2VecKeyedVectors.load(word2vec_file_path)\n",
    "#word_vectors2 = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000) #인코딩문제난다.\n",
    "vector = word_vectors2.wv['사랑']\n",
    "#vector2 = word_vectors['헉']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d47a0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x7fe1f44a7a30>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors #기존에 사용한 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a4aa463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x7fe125a2f370>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors2 # word2vec 임베딩.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d038e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('이별', 0.7626414895057678),\n",
       " ('행복', 0.7550068497657776),\n",
       " ('슬픔', 0.7381505966186523),\n",
       " ('유혹', 0.7238055467605591),\n",
       " ('그리움', 0.7167419195175171),\n",
       " ('추억', 0.7143999338150024),\n",
       " ('꿈', 0.7089294195175171),\n",
       " ('애정', 0.7066588997840881),\n",
       " ('포옹', 0.7034594416618347),\n",
       " ('마음', 0.6972615718841553)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors2.wv.similar_by_word('사랑') #word_vectors.wv 가 keyedvectors가 되서 이걸로 쭉 사용하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a12c581f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vectors2.wv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f15688cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 100  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word_vectors2.wv:\n",
    "        embedding_matrix[i] = word_vectors2.wv[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b1e6e143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_25 (Embedding)     (None, 41, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 41)                23288     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 16)                672       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,023,977\n",
      "Trainable params: 1,023,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 100   # 워드 벡터의 차원 수 \n",
    "\n",
    "# 모델 구성\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "\n",
    "model.add(tf.keras.layers.LSTM(41)) \n",
    "#model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "#model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4e8144a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "247/247 [==============================] - 3s 8ms/step - loss: 0.5088 - accuracy: 0.7422 - val_loss: 0.4126 - val_accuracy: 0.8137\n",
      "Epoch 2/10\n",
      "247/247 [==============================] - 2s 7ms/step - loss: 0.3765 - accuracy: 0.8334 - val_loss: 0.3619 - val_accuracy: 0.8389\n",
      "Epoch 3/10\n",
      "247/247 [==============================] - 2s 7ms/step - loss: 0.3300 - accuracy: 0.8580 - val_loss: 0.3438 - val_accuracy: 0.8497\n",
      "Epoch 4/10\n",
      "247/247 [==============================] - 2s 6ms/step - loss: 0.3022 - accuracy: 0.8719 - val_loss: 0.3352 - val_accuracy: 0.8540\n",
      "Epoch 5/10\n",
      "247/247 [==============================] - 2s 6ms/step - loss: 0.2818 - accuracy: 0.8817 - val_loss: 0.3399 - val_accuracy: 0.8514\n",
      "Epoch 6/10\n",
      "247/247 [==============================] - 2s 6ms/step - loss: 0.2666 - accuracy: 0.8891 - val_loss: 0.3348 - val_accuracy: 0.8576\n",
      "Epoch 7/10\n",
      "247/247 [==============================] - 2s 6ms/step - loss: 0.2511 - accuracy: 0.8979 - val_loss: 0.3341 - val_accuracy: 0.8579\n",
      "Epoch 8/10\n",
      "247/247 [==============================] - 2s 6ms/step - loss: 0.2368 - accuracy: 0.9039 - val_loss: 0.3535 - val_accuracy: 0.8498\n",
      "Epoch 9/10\n",
      "247/247 [==============================] - 2s 6ms/step - loss: 0.2256 - accuracy: 0.9099 - val_loss: 0.3510 - val_accuracy: 0.8574\n",
      "Epoch 10/10\n",
      "247/247 [==============================] - 2s 7ms/step - loss: 0.2121 - accuracy: 0.9168 - val_loss: 0.3594 - val_accuracy: 0.8557\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0548648b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.3729 - accuracy: 0.8518\n",
      "[0.37286147475242615, 0.8518217206001282]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b7879",
   "metadata": {},
   "source": [
    "회고\n",
    "\n",
    "기존에 진행했던것은 영어였지만 이번에 우리가 진행해야하는 언어는 한국어였다.\n",
    "\n",
    "이 과정에서 사용하는 토크나이저도 다르고, 임베딩레이어에 적용할 모델 또한 한국어를 위한 모델을 사용해야했다.\n",
    "\n",
    "NLP쪽은 상당히 어려운내용인것 같다. \n",
    "\n",
    "gensim 유사단어 찾기 한것\n",
    "\n",
    "1537/1537 - 3s - loss: 0.4886 - accuracy: 0.8401\n",
    "[0.4885745644569397, 0.8401041626930237]\n",
    "\n",
    "사전학습 임베딩\n",
    "\n",
    "1537/1537 - 3s - loss: 0.5482 - accuracy: 0.8332\n",
    "[0.5482152700424194, 0.8331875205039978]\n",
    "\n",
    "으로 gensim 유사단어찾기가 더 정확하게 나왔다. 하지만 여기서 모델 하이퍼 파라미터 값을 수정해봐도 변하는 것이 없다.\n",
    "\n",
    "85%넘는 방법이 있을거같은데 찾고있다.\n",
    "\n",
    "--> LSTM을 사용, 41개의 unit으로 사용했다\n",
    "\n",
    "word2vec를 활용해서 네이버 감정리뷰 정확도가 85이상으로 나왔다.\n",
    "\n",
    "1537/1537 - 3s - loss: 0.3729 - accuracy: 0.8518\n",
    "[0.37286147475242615, 0.8518217206001282]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
